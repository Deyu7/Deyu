# app.py â€” GSHS è¡Œä¸ºé—®å· Â· æŠ‘éƒé£é™©é¢„æµ‹ Â· å¯è§†åŒ–
# Usage:
#  
#   streamlit run app.py
#
# å·¦ä¾§ä¾§è¾¹æ å¯é…ç½®ï¼š
# - è¡Œä¸ºæ¨¡å‹ pklï¼šsvm_pca_behavior_pipeline.pkl
# - æ¨¡å‹å…ƒæ•°æ® jsonï¼šsvm_pca_behavior_meta.json
# - åŸå§‹æ•°æ® CSVï¼ˆç”¨äºè®¡ç®—äººç¾¤å‡å€¼/æ ‡å‡†å·®/ç™¾åˆ†ä½ï¼‰
# - ï¼ˆå¯é€‰ï¼‰æ–‡æœ¬æ¨¡å‹ pklï¼špipe_text_final.pkl / pipe_text_final2.pkl
# ---------- START: paste this BEFORE any call to load_dataset ----------
import os
import traceback
import pandas as pd
import streamlit as st

def _detect_file_format(path):
    """Return 'csv', 'xls', 'xlsx', or None."""
    with open(path, "rb") as f:
        head = f.read(4096)
    if head.startswith(b"PK\x03\x04"):
        return "xlsx"
    if head.startswith(b"\xD0\xCF\x11\xE0"):
        return "xls"
    try:
        s = head.decode("utf-8", errors="ignore")
        first = s.splitlines()[0] if s.splitlines() else ""
        if "," in first or "\t" in first:
            return "csv"
    except Exception:
        pass
    return None

def load_dataset(path):
    """
    Robust dataset loader.
    - path: æ–‡ä»¶è·¯å¾„ï¼Œç›¸å¯¹äº repo æ ¹ï¼ˆæˆ–ç»å¯¹è·¯å¾„ï¼‰ã€‚
    è¿”å› pandas.DataFrame æˆ–åœ¨å¤±è´¥æ—¶æŠ›å¼‚å¸¸ï¼ˆä¼šè¢« Streamlit æ•è·å¹¶è®°å½•åˆ°æ—¥å¿—ï¼‰ã€‚
    """
    if not os.path.exists(path):
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{path}")

    fmt = _detect_file_format(path)
# ä¸åœ¨é¡µé¢æ˜¾ç¤ºæ£€æµ‹ä¿¡æ¯ï¼Œæ”¹ä¸ºå†™å…¥åç«¯æ—¥å¿—ï¼ˆä¾¿äºè°ƒè¯•ä½†ä¸æ‰“æ‰° UIï¼‰
print(f"load_dataset: detected format => {fmt}")
    try:
        # ä¼˜å…ˆæŒ‰æ‰©å±•ååˆ¤æ–­ï¼ˆæ›´æ˜ç¡®ï¼‰
        ext = os.path.splitext(path)[1].lower()
        if ext == ".csv" or fmt == "csv":
            df = pd.read_csv(path, low_memory=False)
        elif ext == ".xls" or fmt == "xls":
            # éœ€è¦ xlrd>=2.0.1 åœ¨ requirements.txt ä¸­
            df = pd.read_excel(path, engine="xlrd", low_memory=False)
        elif ext == ".xlsx" or fmt == "xlsx":
            # éœ€è¦ openpyxl åœ¨ requirements.txt ä¸­
            df = pd.read_excel(path, engine="openpyxl", low_memory=False)
        else:
            # å…œåº•ï¼šå…ˆè¯• csvï¼Œå†è¯• excelï¼ˆxlrd/openpyxlï¼‰
            try:
                df = pd.read_csv(path, low_memory=False)
            except Exception:
                df = pd.read_excel(path, engine="xlrd", low_memory=False)
        return df
    except Exception as e:
        tb = traceback.format_exc()
        # è¾“å‡ºåˆ°éƒ¨ç½²æ—¥å¿—ï¼ˆStreamlit çš„åç«¯æ—¥å¿—ï¼‰ï¼Œå¹¶åœ¨ UI æ˜¾ç¤ºç®€çŸ­ä¿¡æ¯
        print("load_dataset error traceback:\n", tb)
        st.error("è¯»å–æ•°æ®é›†å¤±è´¥ï¼ˆè¯¦ç»†ä¿¡æ¯è§éƒ¨ç½²æ—¥å¿—ï¼‰ã€‚")
        raise

# ---------- END: paste this BEFORE any call to load_dataset ----------

import platform, streamlit as st
st.sidebar.caption(f"Python: {platform.python_version()}")

import joblib
import streamlit as st
import plotly.graph_objects as go
import plotly.express as px


import json, os
from pathlib import Path
import numpy as np
import pandas as pd

st.sidebar.caption(
    "ç¯å¢ƒç‰ˆæœ¬ï¼š"
    f" numpy {np.__version__} | pandas {pd.__version__}"
)
try:
    import sklearn, plotly  # noqa
    import joblib as _joblib
    st.sidebar.caption(
        f" scikit-learn {sklearn.__version__} | joblib {jb.__version__}"
    )
except Exception:
    pass


# â€”â€” å®‰å…¨å¯¼å…¥ï¼šjoblib ä¸åœ¨ç¯å¢ƒæ—¶è‡ªåŠ¨å›é€€åˆ° pickleï¼ˆä»…æ­¤ä¸ºæ–°å¢ï¼Œå…¶ä»–é€»è¾‘ä¸å˜ï¼‰
try:
    import joblib as _joblib
except Exception:
    _joblib = None
import pickle as _pickle

import streamlit as st
import plotly.graph_objects as go
import plotly.express as px

st.set_page_config(page_title="é’å°‘å¹´å¿ƒç†å¥åº·é£é™©é¢„æµ‹", page_icon="ğŸ§ ", layout="wide")

# ========= ä»…æ–°å¢ï¼šæŠŠ Qxx æ˜¾ç¤ºä¸ºä¸­æ–‡é¢˜å¹² =========
QUESTION_LABELS = {
    # åŸºæœ¬ä¿¡æ¯
    "Q1": "ä½ çš„å¹´é¾„ï¼Ÿ",
    "Q2": "ä½ çš„æ€§åˆ«ï¼Ÿ",
    "Q3": "ä½ ç°åœ¨çš„å¹´çº§ï¼Ÿ",
    "Q4": "ä¸ç©¿é‹æ—¶çš„èº«é«˜ï¼ˆç±³ï¼‰",
    "Q5": "ä¸ç©¿é‹æ—¶çš„ä½“é‡ï¼ˆå…¬æ–¤ï¼‰",

    # é¥®é£Ÿ/å«ç”Ÿ
    "Q7":  "è¿‡å»30å¤©ï¼Œå› ä¸ºå®¶é‡Œæ²¡æœ‰è¶³å¤Ÿçš„é£Ÿç‰©è€ŒæŒ¨é¥¿çš„é¢‘ç‡",
    "Q9":  "è¿‡å»30å¤©ï¼Œä½ é€šå¸¸æ¯å¤©åƒæ°´æœçš„æ¬¡æ•°",
    "Q10": "è¿‡å»30å¤©ï¼Œä½ é€šå¸¸æ¯å¤©åƒè”¬èœçš„æ¬¡æ•°",
    "Q14": "è¿‡å»30å¤©ï¼Œä½ é€šå¸¸æ¯å¤©åˆ·ç‰™çš„æ¬¡æ•°",
    "Q15": "è¿‡å»30å¤©ï¼Œä½ é¥­å‰æ´—æ‰‹çš„é¢‘ç‡",
    "Q17": "è¿‡å»30å¤©ï¼Œä½ å¦‚å•åæ´—æ‰‹çš„é¢‘ç‡",
    "Q19": "è¿‡å»30å¤©ï¼Œä½ æ´—æ‰‹æ—¶ä½¿ç”¨è‚¥çš‚/é¦™çš‚çš„é¢‘ç‡",

    # æš´åŠ›/ä¼¤å®³ä¸æ¬ºå‡Œ
    "Q23": "è¿‡å»12ä¸ªæœˆï¼Œä½ è¢«äººèº«ä½“æ”»å‡»çš„æ¬¡æ•°",
    "Q24": "è¿‡å»12ä¸ªæœˆï¼Œä½ å‚ä¸è‚¢ä½“å†²çªçš„æ¬¡æ•°",
    "Q25": "è¿‡å»12ä¸ªæœˆï¼Œä½ ä¸¥é‡å—ä¼¤çš„æ¬¡æ•°",
    "Q26": "è¿‡å»12ä¸ªæœˆï¼Œä½ æœ€ä¸¥é‡ä¸€æ¬¡å—ä¼¤æ—¶æ­£åœ¨åšä»€ä¹ˆ",
    "Q27": "è¿‡å»12ä¸ªæœˆï¼Œä½ æœ€ä¸¥é‡ä¸€æ¬¡å—ä¼¤çš„ä¸»è¦åŸå› ",
    "Q28": "è¿‡å»12ä¸ªæœˆï¼Œä½ æœ€ä¸¥é‡ä¸€æ¬¡å—ä¼¤æ˜¯å¦‚ä½•å‘ç”Ÿçš„",
    "Q29": "è¿‡å»12ä¸ªæœˆï¼Œä½ æœ€ä¸¥é‡ä¸€æ¬¡å—ä¼¤çš„ä¼¤æƒ…ç±»å‹",
    "Q30": "è¿‡å»30å¤©ï¼Œä½ è¢«æ¬ºå‡Œçš„å¤©æ•°",
    "Q31": "è¿‡å»30å¤©ï¼Œä½ æœ€å¸¸é­é‡çš„æ¬ºå‡Œæ–¹å¼",

    # å¿ƒç†å¥åº·ï¼ˆå¤šç”¨äºæ ‡ç­¾ï¼Œä¸è¿›ç‰¹å¾ä»¥é˜²æ³„æ¼ï¼‰
    "Q36": "è¿‡å»12ä¸ªæœˆï¼Œä½ æ„Ÿåˆ°å­¤ç‹¬çš„é¢‘ç‡",
    "Q37": "è¿‡å»12ä¸ªæœˆï¼Œä½ å› æ‹…å¿§è€Œæ™šä¸Šæ— æ³•å…¥ç¡çš„é¢‘ç‡",
    "Q38": "è¿‡å»12ä¸ªæœˆï¼Œä½ æ˜¯å¦æŒç»­ä¸¤å‘¨ä»¥ä¸Šå‡ ä¹æ¯å¤©æ„Ÿåˆ°æ‚²ä¼¤/ç»æœ›å¹¶åœæ­¢æ—¥å¸¸æ´»åŠ¨",
    "Q39": "è¿‡å»12ä¸ªæœˆï¼Œä½ æ˜¯å¦è®¤çœŸè€ƒè™‘è¿‡è‡ªæ€",
    "Q40": "è¿‡å»12ä¸ªæœˆï¼Œä½ æ˜¯å¦åˆ¶å®šè¿‡è‡ªæ€è®¡åˆ’",
    "Q41": "ä½ æœ‰å‡ ä¸ªäº²å¯†æœ‹å‹",

    # çƒŸè‰
    "Q44": "ä½ ç¬¬ä¸€æ¬¡å°è¯•å¸çƒŸæ—¶çš„å¹´é¾„",
    "Q45": "è¿‡å»30å¤©ï¼Œä½ å¸çƒŸçš„å¤©æ•°",
    "Q46": "è¿‡å»30å¤©ï¼Œä½ ä½¿ç”¨å…¶ä»–å½¢å¼çƒŸè‰çš„å¤©æ•°",
    "Q47": "è¿‡å»12ä¸ªæœˆï¼Œä½ æ˜¯å¦å°è¯•æˆ’çƒŸ",
    "Q48": "è¿‡å»7å¤©ï¼Œä½ èº«è¾¹æœ‰äººå¸çƒŸçš„å¤©æ•°",
    "Q49": "ä½ çš„çˆ¶æ¯/ç›‘æŠ¤äººæ˜¯å¦ä½¿ç”¨ä»»ä½•å½¢å¼çš„çƒŸè‰",

    # é…’ç²¾/è¯ç‰©
    "Q53": "è¿‡å»30å¤©ï¼Œä½ é¥®é…’ï¼ˆè‡³å°‘ä¸€æ¯ï¼‰çš„å¤©æ•°",
    "Q54": "è¿‡å»30å¤©ï¼Œåœ¨é¥®é…’çš„é‚£äº›å¤©é‡Œï¼Œä½ å¹³å‡æ¯å¤©å–å‡ æ¯",
    "Q55": "è¿‡å»30å¤©ï¼Œä½ é€šå¸¸ä»å“ªé‡Œè·å¾—é…’ç²¾é¥®æ–™",
    "Q56": "ä½ ä¸€ç”Ÿä¸­ï¼Œå–é…’å–åˆ°â€œçœŸçš„é†‰äº†â€çš„æ¬¡æ•°",
    "Q58": "ä½ ä¸€ç”Ÿä¸­ï¼Œå› ä¸ºå–é…’è€Œå®¿é†‰/ä¸é€‚/æƒ¹éº»çƒ¦ç­‰çš„æ¬¡æ•°",
    "Q61": "ä½ ä¸€ç”Ÿä¸­ä½¿ç”¨æ¯’å“ï¼ˆæ‘‡å¤´ä¸¸/MDMA/å†°æ¯’/ç”²åŸºè‹¯ä¸™èƒº/å¤§éº»/æµ·æ´›å› ï¼‰çš„æ¬¡æ•°",

    # ä½“åŠ›æ´»åŠ¨/ä¹…å/é€šå­¦
    "Q67": "è¿‡å»7å¤©ï¼Œä½ æœ‰å¤šå°‘å¤©æ¯å¤©è¿›è¡Œâ‰¥60åˆ†é’Ÿçš„ä½“åŠ›æ´»åŠ¨",
    "Q68": "å¹³å¸¸ä¸€å‘¨ï¼Œä½ æœ‰å¤šå°‘å¤©æ¯å¤©è¿›è¡Œâ‰¥60åˆ†é’Ÿçš„ä½“åŠ›æ´»åŠ¨",
    "Q72": "å…¸å‹çš„ä¸€å¤©ï¼Œä½ åç€ï¼ˆçœ‹ç”µè§†/ç”µè„‘/èŠå¤©/å…¶ä»–ï¼‰çš„æ—¶é—´",
    "Q73": "è¿‡å»7å¤©ï¼Œä½ æœ‰å¤šå°‘å¤©æ­¥è¡Œæˆ–éª‘è‡ªè¡Œè½¦ä¸Šä¸‹å­¦",
    "Q74": "è¿‡å»7å¤©ï¼Œä½ æ¯å¤©å¾€è¿”ä¸Šå­¦é€šå¸¸èŠ±å¤šé•¿æ—¶é—´",
    "Q75": "è¿‡å»30å¤©ï¼Œä½ æ— æ•…ç¼ºè¯¾çš„å¤©æ•°",

    # å­¦æ ¡/å®¶åº­æ”¯æŒ
    "Q76": "è¿‡å»30å¤©ï¼Œä½ å­¦æ ¡é‡Œçš„å¤§å¤šæ•°åŒå­¦æ˜¯å¦å‹å–„å¹¶ä¹äºåŠ©äººï¼ˆé¢‘ç‡ï¼‰",
    "Q77": "è¿‡å»30å¤©ï¼Œä½ çš„çˆ¶æ¯/ç›‘æŠ¤äººæ£€æŸ¥ä½ æ˜¯å¦å®Œæˆä½œä¸šçš„é¢‘ç‡",
    "Q78": "è¿‡å»30å¤©ï¼Œä½ çš„çˆ¶æ¯/ç›‘æŠ¤äººç†è§£ä½ é—®é¢˜å’Œæ‹…å¿§çš„é¢‘ç‡",
    "Q79": "è¿‡å»30å¤©ï¼Œä½ çš„çˆ¶æ¯/ç›‘æŠ¤äººæ˜¯å¦çœŸçš„äº†è§£ä½ ç©ºé—²æ—¶é—´åœ¨åšä»€ä¹ˆï¼ˆé¢‘ç‡ï¼‰",
}
def label_for(col_name: str) -> str:
    text = QUESTION_LABELS.get(str(col_name))
    return f"{text}ï¼ˆ{col_name}ï¼‰" if text else str(col_name)
# =========ï¼ˆæ–°å¢éƒ¨åˆ†ç»“æŸï¼Œå…¶å®ƒä¸€å¾‹ä¸åŠ¨ï¼‰=========

# ========= Sidebar: èµ„æºåŠ è½½ =========
st.sidebar.header("âš™ï¸ é…ç½® / èµ„æº")
model_path = st.sidebar.text_input("è¡Œä¸ºæ¨¡å‹æ–‡ä»¶ï¼ˆ.pklï¼‰", "svm_pca_behavior_pipeline.pkl")
meta_path  = st.sidebar.text_input("è¡Œä¸ºæ¨¡å‹å…ƒæ•°æ®ï¼ˆ.jsonï¼‰", "svm_pca_behavior_meta.json")
data_path  = st.sidebar.text_input("æ•°æ®é›† CSVï¼ˆç”¨äºè®¡ç®—äººç¾¤åŸºçº¿ï¼‰", "CNAH2003_public_use.xls")
text_model_path = st.sidebar.text_input("ï¼ˆå¯é€‰ï¼‰æ–‡æœ¬æ¨¡å‹ï¼ˆ.pklï¼‰", "")

st.sidebar.markdown("---")
st.sidebar.caption("æç¤ºï¼šå…ˆåœ¨ Notebook å¯¼å‡º pkl/jsonï¼›æ•°æ®é›†ä»…ç”¨äºè®¡ç®—å¹³å‡/æ ‡å‡†å·®/ç™¾åˆ†ä½ã€‚")

# ========= å·¥å…·å‡½æ•° =========
@st.cache_data(show_spinner=False)
def load_meta(meta_path: str):
    try:
        meta = json.load(open(meta_path, "r", encoding="utf-8"))
        feats = meta.get("features", [])
        return meta, feats
    except Exception as e:
        st.sidebar.error(f"è¯»å– meta å¤±è´¥ï¼š{e}")
        return {}, []

@st.cache_resource(show_spinner=False)
def load_model(model_path: str):
    try:
        if _joblib is not None:
            return _joblib.load(model_path)
        # å›é€€åˆ° pickleï¼ˆè‹¥ joblib ç¼ºå¤±ï¼‰
        with open(model_path, "rb") as f:
            return _pickle.load(f)
    except Exception as e:
        msg = f"åŠ è½½æ¨¡å‹å¤±è´¥ï¼š{type(e).__name__}: {e}"
        if _joblib is None:
            msg += "ï¼ˆå½“å‰ç¯å¢ƒæœªå®‰è£… joblibï¼Œå·²å°è¯•ä½¿ç”¨ pickle ä½†ä»å¤±è´¥ã€‚è¯·åœ¨ requirements.txt ä¸­æ·»åŠ  joblibï¼‰"
        st.sidebar.error(msg)
        return None

#æ•°æ®
# æ›¿æ¢ä½ åŸæ¥çš„è¯»å–ä»£ç ä¸ºä¸‹é¢è¿™æ®µ
import os
import traceback
import pandas as pd
import streamlit as st

data_path = "CNAH2003_public_use.xls"  # ç¡®è®¤è·¯å¾„ï¼ˆç›¸å¯¹äº repo æ ¹ï¼‰

def detect_file_format(path):
    with open(path, "rb") as f:
        head = f.read(4096)
    # XLSX (zip archive)
    if head.startswith(b"PK\x03\x04"):
        return "xlsx"
    # Old BIFF Compound File (xls)
    if head.startswith(b"\xD0\xCF\x11\xE0"):
        return "xls"
    # Heuristic for CSV / text: first line contains commas or tabs and ASCII letters
    try:
        s = head.decode("utf-8", errors="ignore")
        first = s.splitlines()[0] if s.splitlines() else ""
        if "," in first or "\t" in first:
            return "csv"
    except Exception:
        pass
    return None

if not os.path.exists(data_path):
    st.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{data_path}ã€‚è¯·ç¡®è®¤å·² push åˆ° repo æ ¹ç›®å½•ï¼Œæˆ–ä½¿ç”¨æ­£ç¡®çš„ç›¸å¯¹è·¯å¾„ã€‚")
    raise FileNotFoundError(data_path)

fmt = detect_file_format(data_path)
st.write(f"Detected format: {fmt}")

try:
    if fmt == "csv" or os.path.splitext(data_path)[1].lower() == ".csv":
        df = pd.read_csv(data_path, low_memory=False)
    elif fmt == "xls":
        # .xls éœ€è¦ xlrd>=2.0.1 å·²åœ¨ requirements.txt
        df = pd.read_excel(data_path, engine="xlrd", low_memory=False)
    elif fmt == "xlsx":
        # .xlsx éœ€è¦ openpyxl
        df = pd.read_excel(data_path, engine="openpyxl", low_memory=False)
    else:
        # å…œåº•å°è¯•ï¼šå…ˆç”¨ csvï¼Œå†ç”¨ excel
        try:
            df = pd.read_csv(data_path, low_memory=False)
        except Exception:
            df = pd.read_excel(data_path, engine="xlrd", low_memory=False)
    st.success(f"è¯»å–æˆåŠŸï¼Œå½¢çŠ¶ï¼š{df.shape}")
    st.dataframe(df.head())
except Exception as e:
    # åœ¨ app é¡µé¢æ˜¾ç¤ºå‹å¥½ä¿¡æ¯ï¼Œå¹¶å°†å®Œæ•´ traceback è¾“å‡ºåˆ°æ—¥å¿—ï¼ˆstreamlit æ—¥å¿— / éƒ¨ç½²æ—¥å¿—å¯è§ï¼‰
    st.error("è¯»å–æ•°æ®é›†å¤±è´¥ï¼šè¯¦ç»†é”™è¯¯å·²è®°å½•åˆ°æ—¥å¿—ï¼ˆæŸ¥çœ‹ Manage App -> Logsï¼‰ã€‚")
    tb = traceback.format_exc()
    print(tb)          # ä¼šè¿›å…¥éƒ¨ç½²æ—¥å¿—
    raise



def numeric_bounds(s: pd.Series):
    x = pd.to_numeric(s, errors="coerce")
    x = x[np.isfinite(x)]
    if x.empty:
        return 0.0, 1.0, 0.5
    lo, hi = np.nanpercentile(x, [1, 99])
    mu, sd = np.nanmean(x), np.nanstd(x)
    default = float(mu) if np.isfinite(mu) else float(np.nanmedian(x))
    if not np.isfinite(lo) or not np.isfinite(hi) or lo >= hi:
        lo, hi = float(x.min()), float(x.max())
    if not np.isfinite(default):
        default = (lo + hi) / 2.0
    return float(lo), float(hi), float(default)

def compute_baseline(df: pd.DataFrame, features: list):
    feats_present = [c for c in features if c in df.columns]
    base = {}
    for c in feats_present:
        s = df[c]
        if s.dtype.kind in "biufc":  # numeric-like
            x = pd.to_numeric(s, errors="coerce")
            mu = float(np.nanmean(x))
            sd = float(np.nanstd(x))
            qs = {int(q): float(np.nanpercentile(x, q)) for q in range(1,100)}
            base[c] = {"kind": "num", "mean": mu, "std": sd, "quantiles": qs}
        else:
            vals = s.dropna().astype(str).value_counts().index.tolist()
            vals = vals[:50] if len(vals) > 50 else vals
            base[c] = {"kind": "cat", "choices": vals}
    return base

def zscore(x, mu, sd):
    if sd is None or sd == 0 or not np.isfinite(sd):
        return np.nan
    return (x - mu) / sd

def empirical_percentile(x, qs: dict):
    if not qs:
        return np.nan
    items = sorted(qs.items(), key=lambda kv: kv[0])
    loq, hiq = 1, 99
    for q, v in items:
        if x >= v:
            loq = q
        else:
            hiq = q
            break
    v_lo = qs.get(loq, None)
    v_hi = qs.get(hiq, None)
    if v_lo is None or v_hi is None or v_hi == v_lo:
        return float(loq)
    frac = (x - v_lo) / (v_hi - v_lo)
    return float(np.clip(loq + frac * (hiq - loq), 1, 99))

# ========= åŠ è½½èµ„æº =========
meta, model_features = load_meta(meta_path)
pipe = load_model(model_path)
if pipe is None:
    st.stop()

df_all = load_dataset(data_path)
if df_all is None:
    st.stop()

# ä»…ç”¨æ¨¡å‹ç‰¹å¾å‚ä¸ç»Ÿè®¡ï¼ˆä¿æŒä½ åŸæœ‰ç»“æ„ï¼Œå‡½æ•°åç›¸åŒæ— å‰¯ä½œç”¨ï¼‰
def compute_baseline(df, features):
    feats_present = [c for c in features if c in df.columns]
    base = {}
    for c in feats_present:
        s = df[c]
        if s.dtype.kind in "biufc":
            x = pd.to_numeric(s, errors="coerce")
            mu, sd = float(np.nanmean(x)), float(np.nanstd(x))
            qs = {int(q): float(np.nanpercentile(x, q)) for q in range(1,100)}
            base[c] = {"kind": "num", "mean": mu, "std": sd, "quantiles": qs}
        else:
            vals = s.dropna().astype(str).value_counts().index.tolist()
            base[c] = {"kind": "cat", "choices": vals[:50]}
    return base

baseline = compute_baseline(df_all, model_features)
feats_present = [c for c in model_features if c in baseline]
missing = [c for c in model_features if c not in feats_present]
if missing:
    st.warning(f"ä»¥ä¸‹ç‰¹å¾åœ¨æ•°æ®é›†ä¸­æœªæ‰¾åˆ°ï¼ˆæ§ä»¶å°†ç¼ºå¤±ï¼Œé¢„æµ‹ä»¥ç¼ºå¤±å¤„ç†ï¼‰ï¼š{missing[:12]}{' ...' if len(missing)>12 else ''}")

# ========= é¡µé¢ç»“æ„ =========
st.title("ğŸ§  é’å°‘å¹´å¿ƒç†å¥åº·é£é™©é¢„æµ‹")
st.markdown("æœ¬åº”ç”¨åŸºäºé¢„è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚å·¦ä¾§é…ç½® pkl/json/CSV è·¯å¾„ï¼›å¡«å†™é—®å·åç”Ÿæˆ **æ¦‚ç‡ã€å¼‚å¸¸æŒ‡æ ‡ã€z åˆ†æ•°ã€ç™¾åˆ†ä½ã€åˆ†å¸ƒå®šä½** ç­‰å¯è§†åŒ–ã€‚")

tab_form, tab_result = st.tabs(["ğŸ“ å¡«å†™é—®å·", "ğŸ“Š ç»“æœä¸å¯è§†åŒ–"])

# ========= é—®å·è¾“å…¥ =========
with tab_form:
    st.subheader("1) è¯·å¯¹è¡Œä¸ºé—®å·è¿›è¡Œè¾“å…¥")
    cols = st.columns(2)
    user_input = {}
    for i, c in enumerate(feats_present):
        info = baseline[c]
        with cols[i % 2]:
            if info["kind"] == "num":
                lo, hi, default = numeric_bounds(df_all[c])
                step = 1.0 if (hi - lo) > 5 else 0.1
                # ä½¿ç”¨ä¸­æ–‡é¢˜å¹²
                val = st.slider(label_for(c), min_value=float(np.floor(lo)), max_value=float(np.ceil(hi)),
                                value=float(np.clip(default, lo, hi)), step=step,
                                help=f"å‡å€¼â‰ˆ{default:.2f}ï¼ˆæ•°æ®é›†ä¼°è®¡ï¼‰")
                user_input[c] = val
            else:
                choices = ["<ç¼ºå¤±>"] + info["choices"]
                # ä½¿ç”¨ä¸­æ–‡é¢˜å¹²
                val = st.selectbox(label_for(c), choices, index=0)
                user_input[c] = (None if val == "<ç¼ºå¤±>" else val)

    st.subheader("2) ï¼ˆå¯é€‰ï¼‰è¡Œä¸ºæ—¥å¿— / å¿ƒæƒ…æè¿°ï¼ˆè‡ªç”±æ–‡æœ¬ï¼‰")
    st.caption("å¦‚æä¾›æ–‡æœ¬æ¨¡å‹ pklï¼Œæ­¤å¤„æ–‡æœ¬å°†å¾—åˆ°ä¸€ä¸ªâ€œæ–‡æœ¬é£é™©æ¦‚ç‡â€ï¼Œå†ä¸è¡Œä¸ºæ¦‚ç‡åŠ æƒèåˆã€‚")
    text_input = st.text_area("è¾“å…¥æœ€è¿‘ä¸€å‘¨çš„æƒ…å†µï¼ˆå¯ç•™ç©ºï¼‰", height=140, placeholder="ä¾‹ï¼šæœ€è¿‘ä½œæ¯ä¸è§„å¾‹ï¼Œæ™šä¸Šåˆ·æ‰‹æœºåˆ°å¾ˆæ™šï¼›ä¸Šè¯¾å®¹æ˜“åˆ†å¿ƒâ€¦â€¦")
    w_behavior = st.slider("èåˆåŠ æƒï¼ˆè¡Œä¸ºæ¦‚ç‡æƒé‡ï¼‰", 0.0, 1.0, 0.7, 0.05)
    submitted = st.button("ğŸš€ ç”Ÿæˆé¢„æµ‹ä¸å›¾è¡¨", type="primary")

# ========= é¢„æµ‹ä¸å¯è§†åŒ– =========
if submitted:
    with tab_result:
        st.subheader("é¢„æµ‹ç»“æœ")
        X_one = pd.DataFrame([{c: user_input.get(c, np.nan) for c in model_features}])
        try:
            proba_behavior = float(pipe.predict_proba(X_one)[0, 1])
        except Exception as e:
            st.error(f"è¡Œä¸ºæ¦‚ç‡è®¡ç®—å¤±è´¥ï¼š{e}")
            st.stop()

        proba_text = None
        if text_model_path and Path(text_model_path).exists() and text_input.strip():
            try:
                if _joblib is not None:
                    pipe_text = _joblib.load(text_model_path)
                else:
                    with open(text_model_path, "rb") as f:
                        pipe_text = _pickle.load(f)
                proba_text = float(pipe_text.predict_proba(pd.Series([text_input]))[0, 1])
            except Exception as e:
                st.warning(f"æ–‡æœ¬æ¨¡å‹ä¸å¯ç”¨ï¼š{e}")

        if proba_text is not None:
            w_text = 1.0 - w_behavior
            proba_final = w_behavior * proba_behavior + w_text * proba_text
            st.caption(f"èåˆæ¦‚ç‡ = è¡Œä¸º {w_behavior:.2f} Ã— {proba_behavior:.3f} + æ–‡æœ¬ {w_text:.2f} Ã— {proba_text:.3f}")
        else:
            proba_final = proba_behavior
            st.caption("æœªæä¾›æ–‡æœ¬æ¨¡å‹æˆ–æ–‡æœ¬ä¸ºç©ºï¼šä»…ä½¿ç”¨è¡Œä¸ºæ¦‚ç‡ã€‚")

        if proba_final >= 0.6:
            verdict = "ğŸ”´ é«˜é£é™©ï¼ˆå»ºè®®å°½å¿«è”ç³»ä¸“ä¸šäººå£«/å­¦æ ¡å¿ƒç†ä¸­å¿ƒï¼‰"
        elif proba_final >= 0.3:
            verdict = "ğŸŸ¡ é¢„è­¦ï¼ˆå»ºè®®è¿›è¡Œçº¿ä¸Šéšè®¿æˆ–å¹²é¢„ï¼‰"
        else:
            verdict = "ğŸŸ¢ å®‰å…¨ï¼ˆå»ºè®®ç»´æŒè‰¯å¥½ä½œæ¯ä¸æ”¯æŒï¼‰"

        g = go.Figure(go.Indicator(
            mode="gauge+number",
            value=proba_final*100,
            number={'suffix': '%', 'font': {'size': 36}},
            gauge={
                'axis': {'range': [0, 100]},
                'bar': {'color': '#636EFA'},
                'steps': [
                    {'range': [0, 30], 'color': '#E8F5E9'},
                    {'range': [30, 60], 'color': '#FFF9C4'},
                    {'range': [60, 100], 'color': '#FFEBEE'},
                ],
                'threshold': {'line': {'color': 'red', 'width': 3}, 'thickness': 0.75, 'value': 60}
            },
            title={'text': "æ€»ä½“é£é™©æ¦‚ç‡"}
        ))
        st.plotly_chart(g, use_container_width=True)
        st.success(f"åˆ¤å®šï¼š{verdict}")

        st.markdown("---")
        st.subheader("ä¸ªä½“ä½ç½® Â· åå·®ä¸ç™¾åˆ†ä½")

        rows = []
        for c in feats_present:
            info = baseline[c]
            val = user_input.get(c, None)
            if val is None or (isinstance(val, float) and not np.isfinite(val)):
                continue
            if info["kind"] == "num":
                mu, sd = info.get("mean"), info.get("std")
                z = zscore(float(val), mu, sd)
                pct = empirical_percentile(float(val), info.get("quantiles", {}))
                rows.append({"feature": c, "value": val, "mean": mu, "std": sd, "z": z, "percentile": pct})
        rep = pd.DataFrame(rows).sort_values("z", key=lambda s: np.abs(s), ascending=False)

        if rep.empty:
            st.info("æš‚æ— å¯è®¡ç®— z åˆ†æ•°çš„æ•°å€¼å‹ç‰¹å¾ï¼ˆå¯èƒ½å…¨éƒ¨ä¸ºåˆ†ç±»é¢˜ï¼‰ã€‚")
        else:
            topK = min(15, len(rep))
            fig = px.bar(rep.head(topK), x="z", y="feature", orientation="h",
                         color=rep.head(topK)["z"].apply(lambda v: "é«˜äºå‡å€¼" if v>=0 else "ä½äºå‡å€¼"),
                         color_discrete_map={"é«˜äºå‡å€¼":"#EF553B", "ä½äºå‡å€¼":"#00CC96"},
                         title=f"è¡Œä¸ºæŒ‡æ ‡ z åˆ†æ•°ï¼ˆTop {topK} |z|ï¼‰")
            fig.update_layout(yaxis=dict(title="ç‰¹å¾"), xaxis=dict(title="z åˆ†æ•°"))
            st.plotly_chart(fig, use_container_width=True)

            fig2 = px.bar(rep.head(topK), x="percentile", y="feature", orientation="h",
                          range_x=[0,100], title="è¡Œä¸ºæŒ‡æ ‡ç™¾åˆ†ä½ï¼ˆTop å½±å“é¡¹ï¼‰")
            st.plotly_chart(fig2, use_container_width=True)

            rep["abs_z"] = rep["z"].abs()
            flagged = rep[rep["abs_z"] >= 2].copy()
            if flagged.empty:
                st.info("æœªå‘ç° |z| â‰¥ 2 çš„å¼‚å¸¸æŒ‡æ ‡ã€‚")
            else:
                st.warning("âš ï¸ å¼‚å¸¸æŒ‡æ ‡ï¼ˆ|z| â‰¥ 2ï¼‰")
                st.dataframe(flagged[["feature","value","mean","std","z","percentile"]], use_container_width=True)

        st.markdown("â€”")
        with st.expander("ğŸ“ æŸ¥çœ‹äººç¾¤åˆ†å¸ƒå®šä½ï¼ˆæœ€å¤š 6 ä¸ªæ•°å€¼é¢˜ï¼‰", expanded=False):
            numeric_feats = [c for c in feats_present if baseline[c]["kind"]=="num"]
            pick = st.multiselect("é€‰æ‹©è¦å±•ç¤ºçš„ç‰¹å¾ï¼ˆæœ€å¤š 6 ä¸ªï¼‰", numeric_feats, default=numeric_feats[:6], max_selections=6)
            cols3 = st.columns(3)
            for i, c in enumerate(pick):
                with cols3[i%3]:
                    x = pd.to_numeric(df_all[c], errors="coerce")
                    figd = px.histogram(x.dropna(), nbins=30, title=c)
                    v = user_input.get(c, None)
                    if v is not None and np.isfinite(float(v)):
                        figd.add_vline(x=float(v), line_color="red")
                    st.plotly_chart(figd, use_container_width=True)

        if proba_text is not None:
            st.markdown("---")
            st.subheader("æ–‡æœ¬é€šé“ï¼ˆå¯é€‰ï¼‰")
            st.write(f"æ–‡æœ¬é£é™©æ¦‚ç‡ï¼š**{proba_text:.3f}**ï¼ˆèåˆæŒ‰ä¾§è¾¹æ æƒé‡ï¼‰")
            st.caption("è¯´æ˜ï¼šæ–‡æœ¬æ¨¡å‹ä¸º TF-IDF + LogisticRegressionï¼›éœ€åœ¨ä¾§è¾¹æ å¡«å…¥ pkl è·¯å¾„ã€‚")

        st.markdown("---")
        st.subheader("å¯¼å‡º")
        if rep is not None and not rep.empty:
            csv = rep.to_csv(index=False).encode("utf-8")
            st.download_button("ä¸‹è½½ä¸ªäººåå·®æŠ¥å‘Šï¼ˆCSVï¼‰", data=csv, file_name="individual_deviation_report.csv", mime="text/csv")
